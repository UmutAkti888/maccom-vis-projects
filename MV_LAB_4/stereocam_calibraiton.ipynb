{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python-headless\n",
    "# encountered an issue regarding its version while downloading on PC.\n",
    "# Also, update all required frameworks and libraries to the latest versions to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from IPython.display import display, Javascript\n",
    "#from google.colab.output import eval_js\n",
    "import time\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to generate your custom checkerboard https://markhedleyjones.com/projects/calibration-checkerboard-collection ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkerboard properties\n",
    "CHECKERBOARD = (8, 6)  # 8x6 vertices (the points between squares)\n",
    "SQUARE_SIZE = 25  # Size of squares in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termination criteria for corner refinement\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object points (0,0,0), (1,0,0), (2,0,0), ... in world coordinates\n",
    "objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "objp *= SQUARE_SIZE  # Scale to square size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points\n",
    "objpoints = []  # 3d points in real world space\n",
    "imgpoints = []  # 2d points in image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for captured images\n",
    "if not os.path.exists(\"calib_images\"):\n",
    "    os.makedirs(\"calib_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JavaScript to capture an image\n",
    "# cv.read (for reading the camera)\n",
    "# designed for usage via browser\n",
    "# define the port and the device wihle using offline\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "    js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture Image';\n",
    "      div.appendChild(capture);\n",
    "      document.body.appendChild(div);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await new Promise((resolve) => video.onloadedmetadata = resolve);\n",
    "      video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getTracks().forEach(track => track.stop());\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "    display(js)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = base64.b64decode(data.split(',')[1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(binary)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing calib_images/image_1.jpg\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality) {\n      const div = document.createElement('div');\n      const capture = document.createElement('button');\n      capture.textContent = 'Capture Image';\n      div.appendChild(capture);\n      document.body.appendChild(div);\n\n      const video = document.createElement('video');\n      video.style.display = 'block';\n      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n      div.appendChild(video);\n      video.srcObject = stream;\n      await new Promise((resolve) => video.onloadedmetadata = resolve);\n      video.play();\n\n      // Resize the output to fit the video element.\n      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n      await new Promise((resolve) => capture.onclick = resolve);\n\n      const canvas = document.createElement('canvas');\n      canvas.width = video.videoWidth;\n      canvas.height = video.videoHeight;\n      canvas.getContext('2d').drawImage(video, 0, 0);\n      stream.getTracks().forEach(track => track.stop());\n      div.remove();\n      return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'eval_js' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalib_images/image_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCapturing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtake_photo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Pause to allow user to position the checkerboard\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 38\u001b[0m, in \u001b[0;36mtake_photo\u001b[1;34m(filename, quality)\u001b[0m\n\u001b[0;32m      6\u001b[0m js \u001b[38;5;241m=\u001b[39m Javascript(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124masync function takePhoto(quality) \u001b[39m\u001b[38;5;124m{\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m  const div = document.createElement(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m);\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     37\u001b[0m display(js)\n\u001b[1;32m---> 38\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43meval_js\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtakePhoto(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(quality))\n\u001b[0;32m     39\u001b[0m binary \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eval_js' is not defined"
     ]
    }
   ],
   "source": [
    "# Capture 10 images\n",
    "# Take photo does not work.\n",
    "for i in range(10):\n",
    "    filename = f'calib_images/image_{i+1}.jpg'\n",
    "    print(f'Capturing {filename}')\n",
    "    take_photo(filename)\n",
    "    time.sleep(2)  # Pause to allow user to position the checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load captured images\n",
    "images = [f'calib_images/image_{i+1}.jpg' for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inititate Image Processing Algorithms ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m      2\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(fname)\n\u001b[1;32m----> 3\u001b[0m     gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Find the chessboard corners\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     ret, corners \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindChessboardCorners(gray, CHECKERBOARD, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Gray conversion does not work.\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "        cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform camera calibration\n",
    "ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Camera Matrix:\")\n",
    "print(camera_matrix)\n",
    "print(\"\\nDistortion Coefficients:\")\n",
    "print(dist_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort a sample image\n",
    "img = cv2.imread(images[2]) # Choose the picture (0,9).\n",
    "h, w = img.shape[:2]\n",
    "new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 1, (w, h))\n",
    "undistorted_img = cv2.undistort(img, camera_matrix, dist_coeffs, None, new_camera_matrix)\n",
    "\n",
    "# Show original vs undistorted image\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "axs[1].imshow(cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title(\"Undistorted Image\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Size Estimation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Object Size Estimation ----\n",
    "def measure_object_size(image_path, camera_matrix, dist_coeffs, square_size=SQUARE_SIZE):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    undistorted_img = cv2.undistort(img, camera_matrix, dist_coeffs, None, camera_matrix)\n",
    "\n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(undistorted_img, 50, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        print(\"No object detected.\")\n",
    "        return\n",
    "\n",
    "    # Find the largest contour (assumed to be the marker)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "    # Calculate real-world size based on checkerboard square size\n",
    "    pixel_per_mm = w / (CHECKERBOARD[0] * square_size)\n",
    "    real_width = w / pixel_per_mm\n",
    "    real_height = h / pixel_per_mm\n",
    "\n",
    "    print(f\"Estimated Object Size (Width, Height): {real_width:.2f} mm x {real_height:.2f} mm\")\n",
    "\n",
    "    # Draw bounding box and display\n",
    "    cv2.rectangle(undistorted_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2_imshow(undistorted_img)\n",
    "\n",
    "# Apply object size measurement to an image\n",
    "measure_object_size(images[0], camera_matrix, dist_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
