{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B31MV - Lab 2 (Week 5)\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Visual Words (BoVW) image classification\n",
    "------------------------------------------------\n",
    "BoVW is a feature extraction technique used in image classification. It treats local features in an image (e.g., edges, corners) like words in a document and builds a \"visual vocabulary.\" Images are then represented as histograms of these visual words, which can be fed into a machine learning model for classification.\n",
    "\n",
    "Reference Video: https://www.youtube.com/watch?v=jjQetJtQDS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Extracting dataset...\n",
      "Dataset ready.\n"
     ]
    }
   ],
   "source": [
    "## Extracting dataset\n",
    "\n",
    "url = \"https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip\"\n",
    "dataset_path = \"./caltech-101.zip\"\n",
    "dataset_extract_path = \"./caltech-101\"\n",
    "\n",
    "if not os.path.exists(dataset_extract_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./\")\n",
    "    print(\"Dataset ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset...\n",
      "Dataset ready.\n"
     ]
    }
   ],
   "source": [
    "archive_path = \"./caltech-101/101_ObjectCategories.tar.gz\"\n",
    "dataset_extract_path = \"./101_ObjectCategories\"\n",
    "\n",
    "if not os.path.exists(dataset_extract_path):\n",
    "    print(\"Extracting dataset...\")\n",
    "    with tarfile.open(archive_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=\"./\")\n",
    "    print(\"Dataset ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"airplanes\", \"Motorbikes\", \"Faces\", \"watch\"]\n",
    "image_size = (150, 150)  # Resize images to fixed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(category):\n",
    "    images = []\n",
    "    category_path = os.path.join(dataset_extract_path, category)\n",
    "    if not os.path.exists(category_path):\n",
    "        return []\n",
    "    for img_name in os.listdir(category_path)[:50]:  # Load 50 images per category\n",
    "        img_path = os.path.join(category_path, img_name)\n",
    "        try:\n",
    "            img = io.imread(img_path)\n",
    "            img = rgb2gray(img)  # Convert to grayscale\n",
    "            img = resize(img, image_size)  # Resize\n",
    "            images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "image_data = []\n",
    "labels = []\n",
    "for label, category in enumerate(categories):\n",
    "    imgs = load_images(category)\n",
    "    image_data.extend(imgs)\n",
    "    labels.extend([label] * len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "image_data = np.array(image_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 3: Visualize Sample Images\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
